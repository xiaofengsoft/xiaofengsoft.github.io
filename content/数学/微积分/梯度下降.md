---
date: 2024-12-23
title: 梯度下降
---

## Hessian矩阵

Hessian 矩阵是描述一个标量函数的二阶导数信息的方阵，反映了函数在各个方向上的曲率。它在多元函数的优化问题中扮演着重要角色，特别是当我们需要分析函数的凹凸性或寻找极值点时。

对于一个标量函数 $f(x_1, x_2, \ldots, x_n)$，其 Hessian 矩阵 $H$ 定义为：
$$
H = \left[ \begin{array}{ccc}
\frac{\partial^2 f}{\partial x_1^2} & \cdots & \frac{\partial^2 f}{\partial x_1 \partial x_n} \\
\vdots & \ddots & \vdots \\
\frac{\partial^2 f}{\partial x_n \partial x_1} & \cdots & \frac{\partial^2 f}{\partial x_n^2}
\end{array} \right]
$$
其中

- $H_{ij} = \frac{\partial^2 f}{\partial x_i \partial x_j}$，表示函数 $f$ 对 $x_i$ 和 $x_j$ 的二阶偏导数。
- Hessian 矩阵是一个对称矩阵（如果f的二阶连续可微，$
\frac{\partial^2 f}{\partial x_i \partial x_j} = \frac{\partial^2 f}{\partial x_j \partial x_i}
​$）。

## 梯度向量

描述一个标量函数的一阶导数信息的矩阵是梯度向量，包含标量函数对每个变量的偏导数。
对于一个标量函数 $f(x_1, x_2, \ldots, x_n)$，其梯度 $∇f(x)$ 定义为：
$$
∇f(x) = \left[ \begin{array}{c}
\frac{\partial f}{\partial x_1} \\
\vdots \\
\frac{\partial f}{\partial x_n}
\end{array} \right]
$$
其中

- $∇f(x)$ 是一个列向量，包含函数 $f$ 对每个变量的偏导数。

## 雅可比矩阵

对于向量值函数 $\mathbf{f}(\mathbf{x}) = [f_1(\mathbf{x}), f_2(\mathbf{x}), \ldots, f_m(\mathbf{x})]$，其雅可比矩阵 $J$ 定义为：
$$
J = \left[ \begin{array}{ccc}
\frac{\partial f_1}{\partial x_1} & \cdots & \frac{\partial f_1}{\partial x_n} \\
\vdots & \ddots & \vdots \\
\frac{\partial f_m}{\partial x_1} & \cdots & \frac{\partial f_m}{\partial x_n}
\end{array} \right]
$$
其中

- $J_{ij} = \frac{\partial f_i}{\partial x_j}$，表示函数 $f_i$ 对 $x_j$ 的偏导数。
- 雅可比矩阵是一个 $m \times n$ 的矩阵，其中 $m$ 是函数 $\mathbf{f}$ 的输出维度，$n$ 是函数 $\mathbf{f}$ 的输入维度。
